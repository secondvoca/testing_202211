{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data', download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_data)\n",
    "indices = torch.randperm(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = int(valid_size * n)\n",
    "train_indices = indices[:mid]\n",
    "valid_indices = indices[mid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "  nn.Linear(784, 512),\n",
    "  nn.ReLU(),\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(512, 512),\n",
    "  nn.ReLU(),\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training loss: 0.4364, validation loss: 0.3884\n",
      "epoch: 1, training loss: 0.2851, validation loss: 0.1815\n",
      "epoch: 2, training loss: 0.151, validation loss: 0.116\n",
      "epoch: 3, training loss: 0.113, validation loss: 0.0918\n",
      "epoch: 4, training loss: 0.09533, validation loss: 0.08107\n",
      "epoch: 5, training loss: 0.08524, validation loss: 0.07355\n",
      "epoch: 6, training loss: 0.07932, validation loss: 0.06773\n",
      "epoch: 7, training loss: 0.07358, validation loss: 0.06403\n",
      "epoch: 8, training loss: 0.06991, validation loss: 0.06093\n",
      "epoch: 9, training loss: 0.06633, validation loss: 0.05755\n",
      "epoch: 10, training loss: 0.06387, validation loss: 0.05501\n",
      "epoch: 11, training loss: 0.06015, validation loss: 0.05279\n",
      "epoch: 12, training loss: 0.0582, validation loss: 0.05021\n",
      "epoch: 13, training loss: 0.05553, validation loss: 0.0483\n",
      "epoch: 14, training loss: 0.05337, validation loss: 0.04663\n",
      "epoch: 15, training loss: 0.0516, validation loss: 0.04464\n",
      "epoch: 16, training loss: 0.05001, validation loss: 0.0432\n",
      "epoch: 17, training loss: 0.04784, validation loss: 0.04136\n",
      "epoch: 18, training loss: 0.04645, validation loss: 0.03966\n",
      "epoch: 19, training loss: 0.045, validation loss: 0.03841\n",
      "epoch: 20, training loss: 0.04356, validation loss: 0.03713\n",
      "epoch: 21, training loss: 0.0414, validation loss: 0.03549\n",
      "epoch: 22, training loss: 0.04048, validation loss: 0.03443\n",
      "epoch: 23, training loss: 0.0394, validation loss: 0.0334\n",
      "epoch: 24, training loss: 0.03756, validation loss: 0.0319\n",
      "epoch: 25, training loss: 0.03669, validation loss: 0.03099\n",
      "epoch: 26, training loss: 0.03565, validation loss: 0.02978\n",
      "epoch: 27, training loss: 0.03413, validation loss: 0.0288\n",
      "epoch: 28, training loss: 0.03308, validation loss: 0.02775\n",
      "epoch: 29, training loss: 0.03251, validation loss: 0.02688\n",
      "epoch: 30, training loss: 0.03162, validation loss: 0.02609\n",
      "epoch: 31, training loss: 0.03023, validation loss: 0.02495\n",
      "epoch: 32, training loss: 0.02972, validation loss: 0.02442\n",
      "epoch: 33, training loss: 0.02873, validation loss: 0.02339\n",
      "epoch: 34, training loss: 0.02816, validation loss: 0.0227\n",
      "epoch: 35, training loss: 0.02716, validation loss: 0.02204\n",
      "epoch: 36, training loss: 0.0267, validation loss: 0.02107\n",
      "epoch: 37, training loss: 0.02586, validation loss: 0.02039\n",
      "epoch: 38, training loss: 0.02485, validation loss: 0.01993\n",
      "epoch: 39, training loss: 0.02427, validation loss: 0.01924\n",
      "epoch: 40, training loss: 0.02345, validation loss: 0.01839\n",
      "epoch: 41, training loss: 0.0226, validation loss: 0.01774\n",
      "epoch: 42, training loss: 0.02227, validation loss: 0.01717\n",
      "epoch: 43, training loss: 0.02176, validation loss: 0.01673\n",
      "epoch: 44, training loss: 0.02082, validation loss: 0.01617\n",
      "epoch: 45, training loss: 0.02041, validation loss: 0.01544\n",
      "epoch: 46, training loss: 0.01976, validation loss: 0.01506\n",
      "epoch: 47, training loss: 0.0198, validation loss: 0.01475\n",
      "epoch: 48, training loss: 0.0191, validation loss: 0.01395\n",
      "epoch: 49, training loss: 0.01831, validation loss: 0.01352\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "  train_loss, valid_loss = 0.0, 0.0\n",
    "\n",
    "  model.train()\n",
    "  for idx, (data, target) in enumerate(train_loader):\n",
    "    data = data.view(-1, 28*28)\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item() * data.size(0)\n",
    "\n",
    "  model.eval()\n",
    "  for idx, (data, target) in enumerate(valid_loader):\n",
    "    data = data.view(-1, 28*28)\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "  train_loss /= len(train_loader.dataset)\n",
    "  valid_loss /= len(valid_loader.dataset)\n",
    "\n",
    "  print(f'epoch: {epoch}, training loss: {train_loss:>0.4}, validation loss: {valid_loss:>0.4}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.71\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "for idx, (data, target) in enumerate(test_loader):\n",
    "  data = data.view(-1, 28*28)\n",
    "  output = model(data)\n",
    "  _, pred = torch.max(output, 1)\n",
    "  correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "print(f'accuracy: {correct / len(test_data) * 100:>0.4}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcb000cae946c3d61c1628be2686ea3e3aa8a44b2b5b4af9d1b18b841213f41d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

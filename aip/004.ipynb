{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "h_\\theta(x) &= wx + b \\\\\n",
    "parameter \\, \\theta &= (w, b) \\\\\n",
    "\\underset{w, b}{arg\\,min} \\, J(w, b) &= \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_\\theta(x_i) - y_i \\right)^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative with respect to w: 8.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "y = w**2\n",
    "z = 2*y + 5\n",
    "z.backward()\n",
    "print(f'derivative with respect to w: {w.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 4.0\n",
      "derivative with respect to w: 6.0\n",
      "derivative with respect to w: 8.0\n",
      "derivative with respect to w: 10.0\n",
      "derivative with respect to w: 12.0\n",
      "derivative with respect to w: 14.0\n",
      "derivative with respect to w: 16.0\n",
      "derivative with respect to w: 18.0\n",
      "derivative with respect to w: 20.0\n",
      "derivative with respect to w: 22.0\n",
      "derivative with respect to w: 24.0\n",
      "derivative with respect to w: 26.0\n",
      "derivative with respect to w: 28.0\n",
      "derivative with respect to w: 30.0\n",
      "derivative with respect to w: 32.0\n",
      "derivative with respect to w: 34.0\n",
      "derivative with respect to w: 36.0\n",
      "derivative with respect to w: 38.0\n",
      "derivative with respect to w: 40.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs):\n",
    "  z = 2*w\n",
    "  z.backward()\n",
    "  print(f'derivative with respect to w: {w.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n",
      "derivative with respect to w: 2.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs):\n",
    "  z = 2*w\n",
    "  if w.grad is not None:\n",
    "    w.grad.zero_()\n",
    "  z.backward()\n",
    "  print(f'derivative with respect to w: {w.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1.0], [2.0], [3.0]])\n",
    "y_train = torch.FloatTensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 10.10369873046875\n",
      "epoch: 100, cost: 0.12628014385700226\n",
      "epoch: 200, cost: 0.07803339511156082\n",
      "epoch: 300, cost: 0.04821990057826042\n",
      "epoch: 400, cost: 0.02979692816734314\n",
      "epoch: 500, cost: 0.018412666395306587\n",
      "epoch: 600, cost: 0.011377942748367786\n",
      "epoch: 700, cost: 0.007030864711850882\n",
      "epoch: 800, cost: 0.004344642627984285\n",
      "epoch: 900, cost: 0.0026847373228520155\n",
      "epoch: 1000, cost: 0.0016590108862146735\n",
      "epoch: 1100, cost: 0.00102515600156039\n",
      "epoch: 1200, cost: 0.0006334870122373104\n",
      "epoch: 1300, cost: 0.00039145664777606726\n",
      "epoch: 1400, cost: 0.00024189714167732745\n",
      "epoch: 1500, cost: 0.00014947621093597263\n",
      "epoch: 1600, cost: 9.236818732460961e-05\n",
      "epoch: 1700, cost: 5.707731543225236e-05\n",
      "epoch: 1800, cost: 3.526912769302726e-05\n",
      "epoch: 1900, cost: 2.1794496205984615e-05\n",
      "epoch: 2000, cost: 1.346723274764372e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs + 1):\n",
    "  prediction = model(x_train)\n",
    "  cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f'epoch: {epoch}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.9957]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0097], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.9927]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[4.0]])\n",
    "pred_y = model(new_var)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([\n",
    "  [73, 80, 75],\n",
    "  [93, 88, 93],\n",
    "  [89, 91, 90],\n",
    "  [96, 98, 100],\n",
    "  [73, 66, 70],\n",
    "])\n",
    "y_train = torch.FloatTensor([\n",
    "  [152], [185], [180], [196], [142]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 55771.34375\n",
      "epoch: 100, cost: 1.5699758529663086\n",
      "epoch: 200, cost: 1.546587586402893\n",
      "epoch: 300, cost: 1.524176836013794\n",
      "epoch: 400, cost: 1.5026980638504028\n",
      "epoch: 500, cost: 1.4820894002914429\n",
      "epoch: 600, cost: 1.4623559713363647\n",
      "epoch: 700, cost: 1.4433848857879639\n",
      "epoch: 800, cost: 1.4252088069915771\n",
      "epoch: 900, cost: 1.4077284336090088\n",
      "epoch: 1000, cost: 1.3909380435943604\n",
      "epoch: 1100, cost: 1.374792456626892\n",
      "epoch: 1200, cost: 1.3592609167099\n",
      "epoch: 1300, cost: 1.3443008661270142\n",
      "epoch: 1400, cost: 1.3298991918563843\n",
      "epoch: 1500, cost: 1.3160308599472046\n",
      "epoch: 1600, cost: 1.302654504776001\n",
      "epoch: 1700, cost: 1.2897627353668213\n",
      "epoch: 1800, cost: 1.277314305305481\n",
      "epoch: 1900, cost: 1.2652853727340698\n",
      "epoch: 2000, cost: 1.2536617517471313\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  prediction = model(x_train)\n",
    "  cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f'epoch: {epoch}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151.1690]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([\n",
    "  [73, 80, 75],\n",
    "  [93, 88, 93],\n",
    "  [89, 91, 90],\n",
    "  [96, 98, 100],\n",
    "  [73, 66, 70],\n",
    "])\n",
    "y_train = torch.FloatTensor([\n",
    "  [152], [185], [180], [196], [142]\n",
    "])\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 3803.757080078125\n",
      "epoch: 100, cost: 19.77762794494629\n",
      "epoch: 200, cost: 10.526923179626465\n",
      "epoch: 300, cost: 16.52126693725586\n",
      "epoch: 400, cost: 10.940634727478027\n",
      "epoch: 500, cost: 0.166804239153862\n",
      "epoch: 600, cost: 5.324745178222656\n",
      "epoch: 700, cost: 1.8448731899261475\n",
      "epoch: 800, cost: 1.0133192539215088\n",
      "epoch: 900, cost: 3.365233898162842\n",
      "epoch: 1000, cost: 3.4636335372924805\n",
      "epoch: 1100, cost: 0.08630520105361938\n",
      "epoch: 1200, cost: 3.4799530506134033\n",
      "epoch: 1300, cost: 0.7260425686836243\n",
      "epoch: 1400, cost: 2.4101786613464355\n",
      "epoch: 1500, cost: 1.48721182346344\n",
      "epoch: 1600, cost: 1.4005329608917236\n",
      "epoch: 1700, cost: 0.2810766398906708\n",
      "epoch: 1800, cost: 1.058101773262024\n",
      "epoch: 1900, cost: 0.1541774868965149\n",
      "epoch: 2000, cost: 0.1393575817346573\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    x_train, y_train = samples\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f'epoch: {epoch}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[152.2437]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNumbers:\n",
    "  def __init__(self, num) -> None:\n",
    "    self.numbers = [n for n in range(1, num)]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.numbers[idx]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10]\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "cn = CustomNumbers(100)\n",
    "print(cn[5:10])\n",
    "print(len(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, x_data, y_data) -> None:\n",
    "    self.x_data = x_data\n",
    "    self.y_data = y_data\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([\n",
    "  [73, 80, 75],\n",
    "  [93, 88, 93],\n",
    "  [89, 91, 90],\n",
    "  [96, 98, 100],\n",
    "  [73, 66, 70],\n",
    "])\n",
    "y_train = torch.FloatTensor([\n",
    "  [152], [185], [180], [196], [142]\n",
    "])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = MyDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 284.10784912109375\n",
      "epoch: 100, cost: 2.836646318435669\n",
      "epoch: 200, cost: 2.688246965408325\n",
      "epoch: 300, cost: 0.46292975544929504\n",
      "epoch: 400, cost: 1.208670973777771\n",
      "epoch: 500, cost: 0.6055212616920471\n",
      "epoch: 600, cost: 0.22235219180583954\n",
      "epoch: 700, cost: 1.341681957244873\n",
      "epoch: 800, cost: 0.5962480902671814\n",
      "epoch: 900, cost: 0.6527138948440552\n",
      "epoch: 1000, cost: 0.5834510922431946\n",
      "epoch: 1100, cost: 0.2664044201374054\n",
      "epoch: 1200, cost: 0.9981088042259216\n",
      "epoch: 1300, cost: 0.7367954850196838\n",
      "epoch: 1400, cost: 0.4198184311389923\n",
      "epoch: 1500, cost: 0.5225408673286438\n",
      "epoch: 1600, cost: 1.1860970258712769\n",
      "epoch: 1700, cost: 0.24151310324668884\n",
      "epoch: 1800, cost: 0.4935053884983063\n",
      "epoch: 1900, cost: 0.22706818580627441\n",
      "epoch: 2000, cost: 0.3458666205406189\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    x_train, y_train = samples\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f'epoch: {epoch}, cost: {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151.0578]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "print(pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:13:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcb000cae946c3d61c1628be2686ea3e3aa8a44b2b5b4af9d1b18b841213f41d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
